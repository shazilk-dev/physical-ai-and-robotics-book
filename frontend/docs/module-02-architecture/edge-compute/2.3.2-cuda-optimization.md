---
sidebar_position: 2
title: 2.3.2 CUDA Optimization Techniques
---

# 2.3.2 CUDA Optimization - Squeezing Every Drop of Performance

## Introduction

**Problem:** Your YOLOv8 model runs at 15 FPS on Jetson, but you need 30 FPS for real-time obstacle avoidance.

**Solution:** CUDA optimization techniques can **double or triple performance** without changing the model!

In this section, you'll learn:
- Memory coalescing (avoid wasted bandwidth)
- Occupancy optimization (keep GPU busy)
- Kernel fusion (reduce overhead)
- Profiling tools (find bottlenecks)

---

## CUDA Execution Model Review

### Threads, Blocks, and Grids

**Hierarchy:**
```
Grid (entire kernel launch)
 ‚îú‚îÄ Block 0 (up to 1024 threads)
 ‚îÇ   ‚îú‚îÄ Thread 0
 ‚îÇ   ‚îú‚îÄ Thread 1
 ‚îÇ   ‚îî‚îÄ ...
 ‚îú‚îÄ Block 1
 ‚îÇ   ‚îú‚îÄ Thread 0
 ‚îÇ   ‚îî‚îÄ ...
 ‚îî‚îÄ ...
```

**Key Concepts:**
- **Thread:** Executes a single instance of the kernel
- **Block:** Group of threads that can cooperate (share memory)
- **Grid:** All blocks launched for a kernel

**Example: Image Processing (1920√ó1080)**
```cuda
dim3 block(16, 16);  // 256 threads per block
dim3 grid((1920 + 15) / 16, (1080 + 15) / 16);  // 120 √ó 68 blocks

processImage<<<grid, block>>>(image, output);
```

---

## Optimization 1: Memory Coalescing

### The Problem

**GPU Memory Access Pattern Matters!**

**Bad Access (Non-Coalesced):**
```
Thread 0 reads address: 0
Thread 1 reads address: 1024
Thread 2 reads address: 2048
...

Result: 32 separate memory transactions (slow! ‚ùå)
```

**Good Access (Coalesced):**
```
Thread 0 reads address: 0
Thread 1 reads address: 1
Thread 2 reads address: 2
...

Result: 1 memory transaction fetches all data (fast! ‚úÖ)
```

**Performance Impact:** 10-50√ó speed difference!

---

### Example: Matrix Transpose

**Naive Implementation (Non-Coalesced):**
```cuda
__global__ void transposeNaive(float *input, float *output, int width, int height) {
    int x = blockIdx.x * blockDim.x + threadIdx.x;
    int y = blockIdx.y * blockDim.y + threadIdx.y;

    if (x < width && y < height) {
        // BAD: Reading from input is coalesced, but writing to output is NOT!
        output[x * height + y] = input[y * width + x];
        //     ^^^^^^^^^^^^^^^^ ‚Üê Adjacent threads write to strided locations
    }
}
```

**Performance:** 20 GB/s (10√ó slower than peak bandwidth!)

---

**Optimized Implementation (Coalesced with Shared Memory):**
```cuda
__global__ void transposeOptimized(float *input, float *output, int width, int height) {
    __shared__ float tile[32][33];  // 33 to avoid bank conflicts

    int x = blockIdx.x * blockDim.x + threadIdx.x;
    int y = blockIdx.y * blockDim.y + threadIdx.y;

    // Coalesced read from global memory
    if (x < width && y < height) {
        tile[threadIdx.y][threadIdx.x] = input[y * width + x];
    }

    __syncthreads();  // Wait for all threads to finish loading tile

    // Transpose indices for output
    x = blockIdx.y * blockDim.y + threadIdx.x;
    y = blockIdx.x * blockDim.x + threadIdx.y;

    // Coalesced write to global memory
    if (x < height && y < width) {
        output[y * height + x] = tile[threadIdx.x][threadIdx.y];
    }
}
```

**Performance:** 180 GB/s (90% of peak bandwidth! ‚úÖ)

**Key Technique:** Use shared memory as staging buffer ‚Üí transpose within shared memory ‚Üí write coalesced.

---

## Optimization 2: Occupancy

### What is Occupancy?

**Definition:** Percentage of active threads relative to maximum possible.

```
Occupancy = Active Warps / Maximum Warps per SM

Example:
SM has capacity for 64 warps (2048 threads)
Your kernel uses 32 warps
Occupancy = 32 / 64 = 50%
```

**Why it matters:** Low occupancy ‚Üí GPU sits idle ‚Üí wasted performance.

---

### Factors Affecting Occupancy

**1. Threads Per Block**

**Too Few:**
```cuda
kernel<<<1000, 32>>>(...);  // Only 32 threads per block
Occupancy: ~25% (not enough threads to hide latency)
```

**Too Many:**
```cuda
kernel<<<10, 1024>>>(...);  // Max threads per block
Occupancy: May be OK, but limits shared memory per thread
```

**Optimal (Rule of Thumb):**
```cuda
kernel<<<grid, 256>>>(...);  // 256 threads per block
Occupancy: 75-100% (good balance)
```

---

**2. Register Usage**

**High Register Usage:**
```cuda
__global__ void kernelWithManyRegisters() {
    float a, b, c, d, e, f, g, h;  // Uses 8 registers
    ...
    // Compiler may spill to local memory (slow!)
}

Occupancy: 50% (fewer active threads due to register limit)
```

**Optimized:**
```cuda
__global__ void kernelOptimized() {
    // Reuse variables, reduce register pressure
    float temp;
    temp = ...;  // Reuse temp for multiple calculations
}

Occupancy: 100%
```

**Check Register Usage:**
```bash
nvcc --ptxas-options=-v kernel.cu

# Output:
# ptxas info    : Used 24 registers, 0 bytes smem
```

---

**3. Shared Memory Usage**

**Per-SM Shared Memory (Jetson Orin):** 164 KB

**High Shared Memory Usage:**
```cuda
__global__ void kernelWithLargeSharedMem() {
    __shared__ float data[16384];  // 64 KB per block
    ...
}

Blocks per SM: 164 KB / 64 KB = 2 blocks (low occupancy!)
```

**Optimized:**
```cuda
__global__ void kernelOptimized() {
    __shared__ float data[4096];  // 16 KB per block
    ...
}

Blocks per SM: 164 KB / 16 KB = 10 blocks (high occupancy!)
```

---

### Occupancy Calculator

**NVIDIA CUDA Occupancy Calculator:**
```bash
# Install occupancy calculator (included in CUDA Toolkit)
cd $CUDA_HOME/tools/cuda-occupancy-calculator

# Open spreadsheet (Excel/LibreOffice)
# Input:
# - Compute Capability: 8.7 (Jetson Orin)
# - Threads per block: 256
# - Registers per thread: 24
# - Shared memory per block: 16 KB

# Output:
# - Theoretical Occupancy: 87.5%
# - Active Warps: 56 / 64
```

---

## Optimization 3: Kernel Fusion

### The Problem

**Multiple Small Kernels:**
```cuda
kernel1<<<grid, block>>>(input, temp1);  // 10 Œºs
cudaDeviceSynchronize();                 // 50 Œºs (launch overhead!)

kernel2<<<grid, block>>>(temp1, temp2);  // 10 Œºs
cudaDeviceSynchronize();                 // 50 Œºs

kernel3<<<grid, block>>>(temp2, output); // 10 Œºs
cudaDeviceSynchronize();                 // 50 Œºs

Total: 180 Œºs (83% overhead! ‚ùå)
```

---

### Solution: Fuse Kernels

**Single Fused Kernel:**
```cuda
__global__ void fusedKernel(float *input, float *output, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < n) {
        // Kernel 1 logic
        float temp1 = input[idx] * 2.0f;

        // Kernel 2 logic
        float temp2 = temp1 + 5.0f;

        // Kernel 3 logic
        output[idx] = sqrtf(temp2);
    }
}

fusedKernel<<<grid, block>>>(input, output, n);  // 30 Œºs
cudaDeviceSynchronize();                         // 50 Œºs

Total: 80 Œºs (56% faster! ‚úÖ)
```

**Key Benefit:** Eliminates intermediate global memory writes (temp1, temp2 stay in registers).

---

### Real-World Example: Image Preprocessing

**Original Pipeline (3 kernels):**
```cuda
// Kernel 1: RGB to Grayscale
rgbToGray<<<grid, block>>>(input, gray);

// Kernel 2: Gaussian Blur
gaussianBlur<<<grid, block>>>(gray, blurred);

// Kernel 3: Normalize
normalize<<<grid, block>>>(blurred, output);

Total: 5.2 ms (for 1920√ó1080 image)
```

**Fused Pipeline (1 kernel):**
```cuda
__global__ void preprocessImage(uint8_t *input, float *output, int width, int height) {
    int x = blockIdx.x * blockDim.x + threadIdx.x;
    int y = blockIdx.y * blockDim.y + threadIdx.y;

    if (x >= width || y >= height) return;

    int idx = y * width + x;

    // Step 1: RGB to Grayscale
    uint8_t r = input[idx * 3 + 0];
    uint8_t g = input[idx * 3 + 1];
    uint8_t b = input[idx * 3 + 2];
    float gray = 0.299f * r + 0.587f * g + 0.114f * b;

    // Step 2: Gaussian Blur (simplified 3√ó3 kernel)
    float blurred = 0.0f;
    for (int dy = -1; dy <= 1; dy++) {
        for (int dx = -1; dx <= 1; dx++) {
            int nx = x + dx;
            int ny = y + dy;
            if (nx >= 0 && nx < width && ny >= 0 && ny < height) {
                // Recompute grayscale for neighbor (avoids global memory read)
                int nidx = ny * width + nx;
                uint8_t nr = input[nidx * 3 + 0];
                uint8_t ng = input[nidx * 3 + 1];
                uint8_t nb = input[nidx * 3 + 2];
                float ngray = 0.299f * nr + 0.587f * ng + 0.114f * nb;

                float weight = (dx == 0 && dy == 0) ? 0.25f : 0.125f;
                blurred += ngray * weight;
            }
        }
    }

    // Step 3: Normalize (0-255 ‚Üí 0-1)
    output[idx] = blurred / 255.0f;
}

preprocessImage<<<grid, block>>>(input, output, width, height);

Total: 2.1 ms (60% faster! ‚úÖ)
```

---

## Optimization 4: Stream Concurrency

### Overlap Computation and Data Transfer

**Sequential Execution (Slow):**
```cuda
// Copy batch 1 to GPU
cudaMemcpy(d_batch1, h_batch1, size, cudaMemcpyHostToDevice);  // 10 ms

// Process batch 1
kernel<<<grid, block>>>(d_batch1, d_output1);  // 20 ms

// Copy result 1 to CPU
cudaMemcpy(h_output1, d_output1, size, cudaMemcpyDeviceToHost);  // 10 ms

Total for 1 batch: 40 ms
Total for 10 batches: 400 ms
```

---

**Concurrent Execution with Streams (Fast):**
```cuda
cudaStream_t stream[3];
for (int i = 0; i < 3; i++) {
    cudaStreamCreate(&stream[i]);
}

for (int i = 0; i < 10; i++) {
    int s = i % 3;  // Round-robin streams

    // Copy batch i to GPU (async, non-blocking)
    cudaMemcpyAsync(d_batch[s], h_batch[i], size, cudaMemcpyHostToDevice, stream[s]);

    // Process batch i (runs concurrently with copies)
    kernel<<<grid, block, 0, stream[s]>>>(d_batch[s], d_output[s]);

    // Copy result i to CPU (async, non-blocking)
    cudaMemcpyAsync(h_output[i], d_output[s], size, cudaMemcpyDeviceToHost, stream[s]);
}

// Wait for all streams to finish
cudaDeviceSynchronize();

Total for 10 batches: 240 ms (40% faster! ‚úÖ)
```

**Key Insight:** While batch 2 is processing on GPU, batch 1 result is copying to CPU and batch 3 is copying to GPU (pipelining!).

---

## Profiling Tools

### 1. NVIDIA Nsight Systems

**What it does:** Timeline visualization of CPU/GPU activity.

**Install:**
```bash
sudo apt install nsight-systems
```

**Profile Your Application:**
```bash
nsys profile --stats=true ./your_cuda_app

# Output: report.qdrep file
```

**Analyze:**
```bash
nsys-ui report.qdrep  # Opens GUI

# Look for:
# - Kernel launch gaps (wasted time)
# - Memory copy overlaps
# - CPU-GPU synchronization points
```

**Example Output:**
```
Kernel: matrixMul       |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80% GPU time
Kernel: vectorAdd       |‚ñà‚ñà          | 15% GPU time
MemCpy (HtoD)           |‚ñà           |  5% GPU time

Recommendation: Optimize matrixMul (biggest bottleneck)
```

---

### 2. NVIDIA Nsight Compute

**What it does:** Detailed kernel analysis (register usage, occupancy, memory throughput).

**Profile a Specific Kernel:**
```bash
ncu --set full --export report ./your_cuda_app

# Open report
ncu-ui report.ncu-rep
```

**Key Metrics to Check:**

| Metric | Good Value | Meaning |
|--------|------------|---------|
| **SM Efficiency** | > 80% | GPU cores are busy |
| **Occupancy** | > 50% | Enough active threads |
| **Memory Throughput** | > 70% peak BW | Memory bandwidth utilized |
| **Compute Throughput** | > 60% peak | ALUs are utilized |

**Example Report:**
```
Kernel: myKernel
- SM Efficiency: 45% (‚ùå LOW! GPU is idle 55% of the time)
- Occupancy: 25% (‚ùå LOW! Increase threads per block)
- Memory Throughput: 90% (‚úÖ GOOD! Memory access is efficient)

Recommendation: Increase threads per block to 256
```

---

### 3. CUDA Events (Manual Timing)

**Measure Kernel Execution Time:**
```cuda
cudaEvent_t start, stop;
cudaEventCreate(&start);
cudaEventCreate(&stop);

// Record start time
cudaEventRecord(start);

// Launch kernel
myKernel<<<grid, block>>>(data);

// Record stop time
cudaEventRecord(stop);
cudaEventSynchronize(stop);

// Calculate elapsed time
float milliseconds = 0;
cudaEventElapsedTime(&milliseconds, start, stop);

printf("Kernel execution time: %.2f ms\n", milliseconds);

// Cleanup
cudaEventDestroy(start);
cudaEventDestroy(stop);
```

**Use Case:** Quick performance checks without full profiling.

---

## Case Study: Optimizing YOLOv8 Inference

### Initial Performance (Baseline)

**Setup:**
- Model: YOLOv8n (smallest variant)
- Input: 640√ó640 RGB image
- Hardware: Jetson AGX Orin (FP16 mode)

**Baseline Performance:**
```
Inference time: 33 ms per image
FPS: 30.3
GPU utilization: 65%
Memory bandwidth: 45% of peak
```

**Goal:** Achieve 60 FPS (16.7 ms per image).

---

### Optimization Steps

**Step 1: Enable TensorRT (automatic optimization)**
```python
# Convert PyTorch model to TensorRT
import torch
from torch2trt import torch2trt

model = YOLO('yolov8n.pt')
x = torch.ones((1, 3, 640, 640)).cuda()

model_trt = torch2trt(model, [x], fp16_mode=True)

# Benchmark
import time
for _ in range(100):
    start = time.time()
    model_trt(x)
    print(f"Latency: {(time.time() - start) * 1000:.1f} ms")
```

**Result:** 25 ms (25% faster!)

---

**Step 2: Batch Processing**

**Change batch size from 1 to 4:**
```python
x = torch.ones((4, 3, 640, 640)).cuda()  # 4 images at once

model_trt_batch = torch2trt(model, [x], fp16_mode=True, max_batch_size=4)

# Benchmark
for _ in range(100):
    start = time.time()
    model_trt_batch(x)
    latency_per_image = (time.time() - start) * 1000 / 4
    print(f"Latency per image: {latency_per_image:.1f} ms")
```

**Result:** 18 ms per image (45% faster than baseline!)

---

**Step 3: INT8 Quantization (covered in Section 2.3.3)**

**Preview:**
```python
# Use INT8 calibration for 2√ó additional speedup
model_trt_int8 = torch2trt(model, [x], fp16_mode=False, int8_mode=True, int8_calib_dataset=calib_data)

# Result: 12 ms per image (64% faster! ‚úÖ Goal achieved!)
```

---

## Summary

### Key Takeaways

1. ‚úÖ **Memory coalescing** is critical (10-50√ó speed difference!)
2. ‚úÖ **Occupancy > 50%** keeps GPU busy (use 256 threads per block)
3. ‚úÖ **Kernel fusion** eliminates overhead (fewer kernel launches)
4. ‚úÖ **Stream concurrency** overlaps computation and data transfer
5. ‚úÖ **Profiling tools** (Nsight Systems, Nsight Compute) find bottlenecks

---

### Optimization Checklist

- [ ] Profile with Nsight Systems to find slowest kernel
- [ ] Check memory access patterns (coalesced?)
- [ ] Verify occupancy > 50% (use Occupancy Calculator)
- [ ] Fuse small kernels to reduce overhead
- [ ] Use streams for concurrent execution
- [ ] Benchmark before/after to quantify improvement

---

## Practice Problems

### Problem 1: Coalescing Analysis

**Given this kernel:**
```cuda
__global__ void stride Access(float *data, int n, int stride) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        data[idx * stride] = idx;  // Strided access!
    }
}
```

**Questions:**
1. Is this coalesced when stride=1?
2. What about stride=32?
3. How would you fix it?

---

### Problem 2: Occupancy Optimization

**Kernel uses:**
- 48 registers per thread
- 16 KB shared memory per block
- 256 threads per block

**Calculate:**
1. Blocks per SM (Jetson Orin: 164 KB shared memory, 65536 registers per SM)
2. Theoretical occupancy
3. How to improve?

---

## Further Reading

### Recommended Resources

**Official NVIDIA:**
- [CUDA Best Practices Guide](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/)
- [Nsight Systems Documentation](https://docs.nvidia.com/nsight-systems/)
- [Nsight Compute Documentation](https://docs.nvidia.com/nsight-compute/)

**Books:**
- "Programming Massively Parallel Processors" - Hwu et al. (The CUDA Bible)

**Online Courses:**
- NVIDIA DLI: "Fundamentals of Accelerated Computing with CUDA C/C++"

---

## Next Section

Now that you can optimize CUDA kernels, it's time to deploy deep learning models efficiently!

Continue to **[Section 2.3.3: TensorRT Deployment](./2.3.3-tensorrt-deployment.md)** to learn INT8 quantization and model optimization! üöÄ

---

**Section Status:** ‚úÖ Complete
**Estimated Reading Time:** 50 minutes
**Hands-On Profiling:** 40 minutes (requires CUDA code to profile)
